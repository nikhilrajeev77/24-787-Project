{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "## Swapping atom positions for featurizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymatgen\n",
    "from pymatgen.analysis.local_env import VoronoiNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from os import listdir\n",
    "import time \n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D \n",
    "from torch.autograd import Variable\n",
    "\n",
    "comp = ['CoS','CuS','MnS','MoS','RuS','ScS','TiS','VS']\n",
    "\n",
    "\n",
    "####################################################\n",
    "#loading all xyz file names \n",
    "def find_xyz_filenames( path_to_dir, suffix=\".xyz\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]\n",
    "\n",
    "CoS_filenames = find_xyz_filenames('data_xyz/CoS')\n",
    "CuS_filenames = find_xyz_filenames('data_xyz/CuS')\n",
    "MnS_filenames = find_xyz_filenames('data_xyz/MnS')\n",
    "MoS_filenames = find_xyz_filenames('data_xyz/MoS')\n",
    "RuS_filenames = find_xyz_filenames('data_xyz/RuS')\n",
    "ScS_filenames = find_xyz_filenames('data_xyz/ScS')\n",
    "TiS_filenames = find_xyz_filenames('data_xyz/TiS')\n",
    "VS_filenames = find_xyz_filenames('data_xyz/VS')\n",
    "\n",
    "\n",
    "#####################################################\n",
    "#loading the excel file containing the adsorption site and Gibbs free energy\n",
    "def find_xlsx_filenames( path_to_dir, suffix=\".xlsx\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]\n",
    "\n",
    "xlsx_filenames = find_xlsx_filenames('data')\n",
    "\n",
    "\n",
    "\n",
    "######################################################\n",
    "#loading xlsx data loading data for each Compound\n",
    "path ='data/'+xlsx_filenames[0]\n",
    "\n",
    "##reading the data from each sheet\n",
    "df = pd.read_excel(path,sheet_name=0)\n",
    "delta_g_CoS = df[df.columns[0]]\n",
    "ads_CoS = df[df.columns[1]]\n",
    "\n",
    "df = pd.read_excel(path,sheet_name=1)\n",
    "delta_g_CuS = df[df.columns[0]]\n",
    "ads_CuS = df[df.columns[1]]\n",
    "\n",
    "df = pd.read_excel(path,sheet_name=2)\n",
    "delta_g_MnS = df[df.columns[0]]\n",
    "ads_MnS = df[df.columns[1]]\n",
    "\n",
    "df = pd.read_excel(path,sheet_name=3)\n",
    "delta_g_TiS = df[df.columns[0]]\n",
    "ads_TiS = df[df.columns[1]]\n",
    "\n",
    "df = pd.read_excel(path,sheet_name=4)\n",
    "delta_g_RuS = df[df.columns[0]]\n",
    "ads_RuS = df[df.columns[1]]\n",
    "\n",
    "df = pd.read_excel(path,sheet_name=5)\n",
    "delta_g_MoS = df[df.columns[0]]\n",
    "ads_MoS = df[df.columns[1]]\n",
    "\n",
    "df = pd.read_excel(path,sheet_name=6)\n",
    "delta_g_ScS = df[df.columns[0]]\n",
    "ads_ScS = df[df.columns[1]]\n",
    "\n",
    "\n",
    "df = pd.read_excel(path,sheet_name=7)\n",
    "delta_g_VS = df[df.columns[0]]\n",
    "ads_VS = df[df.columns[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###atom swapping\n",
    "\n",
    "import numpy as np\n",
    "from ase.io import read,write\n",
    "\n",
    "repeat_no = 30 # repeating for creating gaussian distribution of data while featurizing\n",
    "\n",
    "# Atom Swapping for all xyz files\n",
    "#using ads and xyz_filenames obtained using pandas in first cell\n",
    "\n",
    "\n",
    "def swappingdata(filenames,ads, stringname,repeat_no):\n",
    "\n",
    "    r = 0\n",
    "    for k in range(0,repeat_no):\n",
    "        for i in range(0,len(filenames)):\n",
    "            \n",
    "            index1=0\n",
    "            index2=ads[i]\n",
    "            wire=read('data_xyz/'+stringname+'/'+str(i)+'.xyz') #reading data from file\n",
    "            wire = wire.repeat((2,2,1)) # creating symmetric copies required for calcuation of coordination number using voronoi\n",
    "            # symbol swap\n",
    "            CS=wire.get_chemical_symbols() #swapping the atom symbols\n",
    "            temp=CS[index1]\n",
    "            CS[index1]=CS[index2]\n",
    "            CS[index2]=temp\n",
    "            wire.set_chemical_symbols(CS)\n",
    "            \n",
    "            #swapping atom positions\n",
    "            wire.positions[[index1,index2]] = wire.positions[[index2,index1]] \n",
    "            \n",
    "            \n",
    "            #writing the updated data into new file\n",
    "            wire.write('swapped_data_for_featurizing/'+stringname+'/'+str(r)+'.xyz') \n",
    "            r+=1\n",
    "            \n",
    "swappingdata(CoS_filenames,ads_CoS,'CoS',repeat_no)  \n",
    "swappingdata(CuS_filenames,ads_CuS,'CuS',repeat_no)  \n",
    "swappingdata(MnS_filenames,ads_MnS,'MnS',repeat_no)  \n",
    "swappingdata(MoS_filenames,ads_MoS,'MoS',repeat_no)  \n",
    "swappingdata(RuS_filenames,ads_RuS,'RuS',repeat_no)  \n",
    "swappingdata(ScS_filenames,ads_ScS,'ScS',repeat_no)  \n",
    "swappingdata(TiS_filenames,ads_TiS,'TiS',repeat_no)  \n",
    "swappingdata(VS_filenames,ads_VS,'VS',repeat_no)  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
